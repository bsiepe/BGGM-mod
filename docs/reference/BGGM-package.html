<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>BGGMmod:  Bayesian Gaussian Graphical Models — BGGMmod-package • BGGMmod</title>

<!-- favicons -->
<link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png" />
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png" />
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png" />
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png" />

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="BGGMmod:  Bayesian Gaussian Graphical Models — BGGMmod-package" />
<meta property="og:description" content="The R package BGGMmod provides tools for making Bayesian inference in
Gaussian graphical models (GGM). The methods are organized around two general approaches for
Bayesian inference: (1) estimation (Williams 2018)
 and (2) hypothesis testing
(Williams and Mulder 2019)
. The key distinction is that the former focuses on either the
posterior or posterior predictive distribution, whereas the latter focuses on model comparison
with the Bayes factor.
The methods in BGGMmod build upon existing algorithms that are well-known in the literature.
The central contribution of BGGMmod is to extend those approaches:

Bayesian estimation with the novel matrix-F prior distribution (Mulder and Pericchi 2018)
.

Estimation estimate.

Bayesian hypothesis testing with the novel matrix-F prior distribution (Mulder and Pericchi 2018)
.

Exploratory hypothesis testing explore.
Confirmatory hypothesis  testing confirm.

Comparing GGMs (Williams et al. 2020)

Partial correlation differences ggm_compare_estimate.
Posterior predictive check ggm_compare_ppc.
Exploratory hypothesis testing ggm_compare_explore.
Confirmatory hypothesis testing ggm_compare_confirm.

Extending inference beyond the conditional (in)dependence structure

Predictability with Bayesian variance explained (Gelman et al. 2019)

      predictability.
Posterior uncertainty in the partial correlations estimate.
Custom Network Statistics roll_your_own.



Furthermore, the computationally intensive tasks are written in c++ via the R
package Rcpp (Eddelbuettel et al. 2011)
 and the c++
library Armadillo (Sanderson and Curtin 2016)
, there are plotting functions
for each method, control variables can be included in the model, and there is support for
missing values bggm_missing.
Supported Data Types:

Continuous: The continuous method was described in  Williams and Mulder (2019)
.
Binary: The binary method builds directly upon in Talhouk et al. (2012)
,
      that, in turn, built upon the approaches of Lawrence et al. (2008)
 and
      Webb and Forster (2008)
 (to name a few).
Ordinal: Ordinal data requires sampling thresholds. There are two approach included in BGGMmod: (1)
the customary approach described in in Albert and Chib (1993)
 (the default) and
the 'Cowles' algorithm described in in Cowles (1996)
.
Mixed: The mixed data (a combination of discrete and continuous) method was introduced
in Hoff (2007)
. This is a semi-parametric copula model
(i.e., a copula GGM) based on the ranked likelihood. Note that this can be used for data
consisting entirely of ordinal data.


Additional Features:
The primary focus of BGGMmod is Gaussian graphical modeling (the inverse covariance matrix).
 The residue is a suite of useful methods not explicitly for GGMs:

Bivariate correlations for binary (tetrachoric), ordinal (polychoric), mixed (rank based),
       and continous (Pearson's) data zero_order_cors.
Multivariate regression for binary (probit), ordinal (probit),
       mixed (rank likelihood), and continous data (estimate).
Multiple regression for binary (probit), ordinal (probit),
       mixed (rank likelihood), and continous data (e.g., coef.estimate).


Note on Conditional (In)dependence Models for Latent Data:
All of the data types (besides continuous) model latent data. That is, unoboserved data that is
assumed to be Gaussian distributed. For example, a  tetrachoric correlation (binary data) is a
special case of a polychoric correlation (ordinal data). Both relations are between &quot;theorized
normally distributed continuous latent variables&quot;
(Wikipedia). In both instances,
the correpsonding partial correlation between observed variables is conditioned
on the remaining variables in the latent space. This implies that interpration
is similar to continuous data, but with respect to latent variables. We refer interested users
to page 2364, section 2.2, in  Webb and Forster (2008)
.

High Dimensional Data?
BGGMmod was builit specificially for social-behvarioal scientists. Of course, the methods
can be used by all researchers. However, there is not support for high-dimensonal data
(i.e., more variables than observations) that are common place in the genetics literature.
These data are rare in the social-behavioral sciences. In the future, support for high-dimensional
data may be added to BGGMmod." />
<meta property="og:image" content="https://donaldrwilliams.github.io/BGGMmod/reference/figures/hex.jpg" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:creator" content="@wdonald_1985" />
<meta name="twitter:site" content="@wdonald_1985" />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">BGGMmod</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">2.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li>
  <a href="../articles/installation.html">Troubleshoot</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/donaldRwilliams/BGGMmod/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>BGGMmod:  Bayesian Gaussian Graphical Models</h1>
    <small class="dont-index">Source: <a href='https://github.com/donaldRwilliams/BGGMmod/blob/master/R/BGGMmod-package.R'><code>R/BGGMmod-package.R</code></a></small>
    <div class="hidden name"><code>BGGMmod-package.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>The <code>R</code> package <strong>BGGMmod</strong> provides tools for making Bayesian inference in
Gaussian graphical models (GGM). The methods are organized around two general approaches for
Bayesian inference: (1) estimation (Williams 2018)
 and (2) hypothesis testing
(Williams and Mulder 2019)
. The key distinction is that the former focuses on either the
posterior or posterior predictive distribution, whereas the latter focuses on model comparison
with the Bayes factor.</p>
<p>The methods in <strong>BGGMmod</strong> build upon existing algorithms that are well-known in the literature.
The central contribution of <strong>BGGMmod</strong> is to extend those approaches:</p>
<ol>
<li><p>Bayesian estimation with the novel matrix-F prior distribution (Mulder and Pericchi 2018)
.</p>
<p></p><ul>
<li><p>Estimation <code><a href='estimate.html'>estimate</a></code>.</p></li>
</ul></li>
<li><p>Bayesian hypothesis testing with the novel matrix-F prior distribution (Mulder and Pericchi 2018)
.</p>
<p></p><ul>
<li><p>Exploratory hypothesis testing <code><a href='explore.html'>explore</a></code>.</p></li>
<li><p>Confirmatory hypothesis  testing <code><a href='confirm.html'>confirm</a></code>.</p></li>
</ul></li>
<li><p>Comparing GGMs (Williams et al. 2020)</p>
<p></p><ul>
<li><p>Partial correlation differences <code><a href='ggm_compare_estimate.html'>ggm_compare_estimate</a></code>.</p></li>
<li><p>Posterior predictive check <code><a href='ggm_compare_ppc.html'>ggm_compare_ppc</a></code>.</p></li>
<li><p>Exploratory hypothesis testing <code><a href='ggm_compare_explore.html'>ggm_compare_explore</a></code>.</p></li>
<li><p>Confirmatory hypothesis testing <code><a href='ggm_compare_confirm.html'>ggm_compare_confirm</a></code>.</p></li>
</ul></li>
<li><p>Extending inference beyond the conditional (in)dependence structure</p>
<ul>
<li><p>Predictability with Bayesian variance explained (Gelman et al. 2019)

      <code><a href='predictability.html'>predictability</a></code>.</p></li>
<li><p>Posterior uncertainty in the partial correlations <code><a href='estimate.html'>estimate</a></code>.</p></li>
<li><p>Custom Network Statistics <code><a href='roll_your_own.html'>roll_your_own</a></code>.</p></li>
</ul></li>
</ol>

<p>Furthermore, the computationally intensive tasks are written in <code>c++</code> via the <code>R</code>
package <strong>Rcpp</strong> (Eddelbuettel et al. 2011)
 and the <code>c++</code>
library <strong>Armadillo</strong> (Sanderson and Curtin 2016)
, there are plotting functions
for each method, control variables can be included in the model, and there is support for
missing values <code><a href='bggm_missing.html'>bggm_missing</a></code>.</p>
<p><b>Supported Data Types</b>:</p>
<ul>
<li><p>Continuous: The continuous method was described in  Williams and Mulder (2019)
.</p></li>
<li><p>Binary: The binary method builds directly upon in Talhouk et al. (2012)
,
      that, in turn, built upon the approaches of Lawrence et al. (2008)
 and
      Webb and Forster (2008)
 (to name a few).</p></li>
<li><p>Ordinal: Ordinal data requires sampling thresholds. There are two approach included in <b>BGGMmod</b>: (1)
the customary approach described in in Albert and Chib (1993)
 (the default) and
the 'Cowles' algorithm described in in Cowles (1996)
.</p></li>
<li><p>Mixed: The mixed data (a combination of discrete and continuous) method was introduced
in Hoff (2007)
. This is a semi-parametric copula model
(i.e., a copula GGM) based on the ranked likelihood. Note that this can be used for data
consisting entirely of ordinal data.</p></li>
</ul>

<p><b>Additional Features</b>:</p>
<p>The primary focus of <code>BGGMmod</code> is Gaussian graphical modeling (the inverse covariance matrix).
 The residue is a suite of useful methods not explicitly for GGMs:</p>
<p></p><ol>
<li><p>Bivariate correlations for binary (tetrachoric), ordinal (polychoric), mixed (rank based),
       and continous (Pearson's) data <code><a href='zero_order_cors.html'>zero_order_cors</a></code>.</p></li>
<li><p>Multivariate regression for binary (probit), ordinal (probit),
       mixed (rank likelihood), and continous data (<code><a href='estimate.html'>estimate</a></code>).</p></li>
<li><p>Multiple regression for binary (probit), ordinal (probit),
       mixed (rank likelihood), and continous data (e.g., <code><a href='coef.estimate.html'>coef.estimate</a></code>).</p></li>
</ol>

<p><strong>Note on Conditional (In)dependence Models for Latent Data</strong>:</p>
<p>All of the data types (besides continuous) model latent data. That is, unoboserved data that is
assumed to be Gaussian distributed. For example, a  tetrachoric correlation (binary data) is a
special case of a polychoric correlation (ordinal data). Both relations are between "theorized
normally distributed continuous <strong>latent</strong> variables"
(<a href='https://en.wikipedia.org/wiki/Polychoric_correlation'>Wikipedia</a>). In both instances,
the correpsonding partial correlation between observed variables is conditioned
on the remaining variables in the <em>latent</em> space. This implies that interpration
is similar to continuous data, but with respect to latent variables. We refer interested users
to page 2364, section 2.2, in  Webb and Forster (2008)
.</p>

<p><strong>High Dimensional Data?</strong></p>
<p><strong>BGGMmod</strong> was builit specificially for social-behvarioal scientists. Of course, the methods
can be used by all researchers. However, there is <em>not</em> support for high-dimensonal data
(i.e., more variables than observations) that are common place in the genetics literature.
These data are rare in the social-behavioral sciences. In the future, support for high-dimensional
data may be added to <strong>BGGMmod</strong>.</p>
    </div>



    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Albert JH, Chib S (1993).
&#8220;Bayesian analysis of binary and polychotomous response data.&#8221;
<em>Journal of the American statistical Association</em>, <b>88</b>(422), 669--679.<br /><br /> Cowles MK (1996).
&#8220;Accelerating Monte Carlo Markov chain convergence for cumulative-link generalized linear models.&#8221;
<em>Statistics and Computing</em>, <b>6</b>(2), 101--111.<br /><br /> Eddelbuettel D, Fran攼㸷ois R, Allaire J, Ushey K, Kou Q, Russel N, Chambers J, Bates D (2011).
&#8220;Rcpp: Seamless R and C++ integration.&#8221;
<em>Journal of Statistical Software</em>, <b>40</b>(8), 1--18.<br /><br /> Gelman A, Goodrich B, Gabry J, Vehtari A (2019).
&#8220;R-squared for Bayesian Regression Models.&#8221;
<em>American Statistician</em>, <b>73</b>(3), 307--309.
ISSN 15372731, doi: <a href='https://doi.org/10.1080/00031305.2018.1549100'>10.1080/00031305.2018.1549100</a>
.<br /><br /> Hoff PD (2007).
&#8220;Extending the rank likelihood for semiparametric copula estimation.&#8221;
<em>The Annals of Applied Statistics</em>, <b>1</b>(1), 265--283.<br /><br /> Lawrence E, Bingham D, Liu C, Nair VN (2008).
&#8220;Bayesian inference for multivariate ordinal data using parameter expansion.&#8221;
<em>Technometrics</em>, <b>50</b>(2), 182--191.<br /><br /> Mulder J, Pericchi L (2018).
&#8220;The Matrix-F Prior for Estimating and Testing Covariance Matrices.&#8221;
<em>Bayesian Analysis</em>, 1--22.
ISSN 19316690, doi: <a href='https://doi.org/10.1214/17-BA1092'>10.1214/17-BA1092</a>
.<br /><br /> Sanderson C, Curtin R (2016).
&#8220;Armadillo: a template-based C++ library for linear algebra.&#8221;
<em>Journal of Open Source Software</em>, <b>1</b>(2), 26.<br /><br /> Talhouk A, Doucet A, Murphy K (2012).
&#8220;Efficient Bayesian inference for multivariate probit models with sparse inverse correlation matrices.&#8221;
<em>Journal of Computational and Graphical Statistics</em>, <b>21</b>(3), 739--757.<br /><br /> Webb EL, Forster JJ (2008).
&#8220;Bayesian model determination for multivariate ordinal and binary data.&#8221;
<em>Computational statistics \&amp; data analysis</em>, <b>52</b>(5), 2632--2649.<br /><br /> Williams DR (2018).
&#8220;Bayesian Estimation for Gaussian Graphical Models: Structure Learning, Predictability, and Network Comparisons.&#8221;
<em>arXiv</em>.
doi: <a href='https://doi.org/10.31234/OSF.IO/X8DPR'>10.31234/OSF.IO/X8DPR</a>
.<br /><br /> Williams DR, Mulder J (2019).
&#8220;Bayesian Hypothesis Testing for Gaussian Graphical Models: Conditional Independence and Order Constraints.&#8221;
<em>PsyArXiv</em>.
doi: <a href='https://doi.org/10.31234/osf.io/ypxd8'>10.31234/osf.io/ypxd8</a>
.<br /><br /> Williams DR, Rast P, Pericchi LR, Mulder J (2020).
&#8220;Comparing Gaussian graphical models with the posterior predictive distribution and Bayesian model selection.&#8221;
<em>Psychological Methods</em>.</p>

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Donald Williams, Joris Mulder.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


